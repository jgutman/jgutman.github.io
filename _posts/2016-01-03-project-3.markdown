---
layout: default
modal-id: 3
date: 2016-01-03
title: Supervised text classification in Reddit posts
img: reddit.001.png
alt: Supervised text classification and relevance detection in Reddit posts
project-date: October - December 2015
institution: New York University
category: Machine learning and natural language processing
description: <p.small>We built a multi-class classifier for determining the optimal subreddit for a particular post given only its text. We were interested in comparing feature extraction methods based on standard bag-of-words approaches to distributed semantic representations constructed using skip-gram neural networks. Embeddings for particular words and Reddit posts as a whole were provided as features to linear classifiers (i.e. support vector machines) in order to predict optimal subreddit labels for each post. Bootstrap samples of the labeled input data were constructed to bias training towards higher quality posts, using proxy measures of post quality and relevance.</p> <p.small>Models trained on traditional bag-of-words feature extraction approaches were compared to two main types of distributed meaning vector-space embedding approaches trained using single-layer neural networks&#58; 1) the word embedding models&mdash;which learned distinct representations for every word in the corpus vocabulary before aggregating these word vectors in a weighted or unweighted manner&mdash; and 2) more complex document embedding neural net models that learned representations for both individual words and whole documents simultaneously.</p> <p.small>Neither distributed neural network approach outperformed the simpler bag-of-words methods, but while these feature extraction methods did not substantially improve performance, they provided a reasonably efficient and scalable method of dimensionality reduction for text data without significant loss of information or decrease in performance.</p><p.small>The analyses and models used in this project were all written in Python using the scikit-learn library for machine learning and text processing, as well as the gensim and nltk for implementation of natural language and distributed models. Visualizations were constructed in R's ggplot2 as well as Python. Data obtained from Kaggle version of publicly available Reddit dataset.</p>
code: https://github.com/jgutman/koding.git
paper: SNLP_writeup_gutman_nam.pdf
slides: SNLP_Presentation.pdf
---
